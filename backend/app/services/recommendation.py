# -*- coding: utf-8 -*-
"""recommendation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/16rbcruLQfeS0mtcFmjQqSoaBv4pZIx9M
"""

import pandas as  pd
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

import warnings
warnings.filterwarnings('ignore')

"""**Importing Datasets**"""

books_data = pd.read_csv('/content/Books.csv',nrows=15000,encoding='latin1', sep=';', on_bad_lines='skip')
ratings_data = pd.read_csv('/content/Book-Ratings.csv',nrows=15000,encoding='latin1', sep=';', on_bad_lines='skip')
users_data = pd.read_csv('/content/Users.csv',encoding='latin1',nrows=15000,sep=';', on_bad_lines='skip')

"""**Overview of the dataset**"""

print("Books Dataset Columns:")
print(books_data.columns)
print("\nBooks Dataset Shape:", books_data.shape)
print("\nBooks Dataset Head:")
print(books_data.head())

print("\n" + "="*80 + "\n")

print("Ratings Dataset Columns:")
print(ratings_data.columns)
print("\nRatings Dataset Shape:", ratings_data.shape)
print("\nRatings Dataset Head:")
print(ratings_data.head())

print("\n" + "="*80 + "\n")

print("Users Dataset Columns:")
print(users_data.columns)
print("\nUsers Dataset Shape:", users_data.shape)
print("\nUsers Dataset Head:")
print(users_data.head())

"""**Merging the Datasets**"""

# Remove ratings with 0 values (implicit feedback - not explicit ratings)
ratings_data = ratings_data[ratings_data["Book-Rating"] > 0]

# Merge ratings with books data to get book titles and authors
merged_df = pd.merge(
    ratings_data,
    books_data,
    on="ISBN"
)

# Merge with users data if needed
merged_df = pd.merge(
    merged_df,
    users_data,
    on="User-ID"
)

print("\n" + "="*80 + "\n")
print("Merged Dataset Head:")
print(merged_df.head().to_string())

print("\nMerged Dataset Shape:", merged_df.shape)

"""**Data Exploration and Statistics**"""

num_users = merged_df["User-ID"].nunique()
num_books = merged_df["ISBN"].nunique()
num_ratings = len(merged_df)

print(f"\nNumber of unique users: {num_users}")
print(f"Number of unique books: {num_books}")
print(f"Total number of ratings: {num_ratings}")

# Ratings per user
ratings_per_user = merged_df.groupby("User-ID")["Book-Rating"].count()
print(f"\nAverage ratings per user: {ratings_per_user.mean():.2f}")
print(f"Max ratings by a user: {ratings_per_user.max()}")
print(f"Min ratings by a user: {ratings_per_user.min()}")

"""**Filter Data for Better Recommendations**"""

# Keep only users with at least 5 ratings and books with at least 2 ratings
min_user_ratings = 3
min_book_ratings = 2

users_with_enough_ratings = ratings_per_user[ratings_per_user >= min_user_ratings].index
merged_df_filtered = merged_df[merged_df["User-ID"].isin(users_with_enough_ratings)]

ratings_per_book = merged_df_filtered.groupby("ISBN")["Book-Rating"].count()
books_with_enough_ratings = ratings_per_book[ratings_per_book >= min_book_ratings].index
merged_df_filtered = merged_df_filtered[merged_df_filtered["ISBN"].isin(books_with_enough_ratings)]

print(f"\n{'='*80}")
print(f"\nAfter filtering (users with ≥{min_user_ratings} ratings, books with ≥{min_book_ratings} ratings):")
print(f"Filtered users: {merged_df_filtered['User-ID'].nunique()}")
print(f"Filtered books: {merged_df_filtered['ISBN'].nunique()}")
print(f"Filtered ratings: {len(merged_df_filtered)}")

"""**Create User-Book Interaction Matrix**"""

user_book_matrix = merged_df_filtered.pivot_table(
    index="User-ID",          # rows = users
    columns="ISBN",           # columns = books
    values="Book-Rating",     # values = ratings
    fill_value=0              # unrated books = 0
)

ratings_matrix = user_book_matrix.to_numpy()
print("\n" + "="*80 + "\n")
print("User-Book Matrix Shape:", ratings_matrix.shape)
print("\nUser-Book Matrix Sample:")
print(ratings_matrix[:5, :5])

# Check non-zero entries
non_zero_count = np.count_nonzero(ratings_matrix)
print(f"\nTotal non-zero ratings in matrix: {non_zero_count}")
print(f"Percentage of ratings: {(non_zero_count / ratings_matrix.size) * 100:.2f}%")

"""**Explore the Interaction Matrix**"""

total_entries = ratings_matrix.size
zero_entries = np.count_nonzero(ratings_matrix == 0)
non_zero_entries = total_entries - zero_entries
sparsity = zero_entries / total_entries
density = non_zero_entries / total_entries

print(f"\nMatrix Statistics:")
print(f"Total possible interactions: {total_entries}")
print(f"Zero interactions: {zero_entries}")
print(f"Non-zero interactions: {non_zero_entries}")
print(f"Sparsity of the interaction matrix: {sparsity:.4f} ({sparsity*100:.2f}%)")
print(f"Density of the interaction matrix: {density:.4f} ({density*100:.2f}%)")

# Rating statistics
non_zero_ratings = ratings_matrix[ratings_matrix > 0]
print(f"\nRating Statistics (non-zero only):")
print(f"Min rating: {np.min(non_zero_ratings):.1f}")
print(f"Max rating: {np.max(non_zero_ratings):.1f}")
print(f"Mean rating: {np.mean(non_zero_ratings):.2f}")
print(f"Median rating: {np.median(non_zero_ratings):.1f}")

"""**Normalize Ratings and Create User Similarity Matrix**"""

# This helps find users with similar rating patterns, not just magnitude
user_means = np.zeros(ratings_matrix.shape[0])
ratings_matrix_normalized = ratings_matrix.copy()

for i in range(ratings_matrix.shape[0]):
    user_ratings = ratings_matrix[i][ratings_matrix[i] > 0]
    if len(user_ratings) > 0:
        user_means[i] = np.mean(user_ratings)
        # Only normalize non-zero ratings
        mask = ratings_matrix[i] > 0
        ratings_matrix_normalized[i][mask] -= user_means[i]

print(f"\nComputing User Similarity Matrix (using normalized ratings)...")
user_similarity = cosine_similarity(ratings_matrix_normalized)
print(f"User Similarity Matrix Shape: {user_similarity.shape}")
print("\nUser Similarity Matrix Sample (first 5x5):")
print(user_similarity[:5, :5])

# Check similarity statistics
off_diagonal = user_similarity[np.triu_indices_from(user_similarity, k=1)]
print(f"\nSimilarity Statistics:")
print(f"Min similarity: {np.min(user_similarity):.4f}")
print(f"Max similarity: {np.max(user_similarity):.4f}")
print(f"Mean similarity (excluding diagonal): {np.mean(off_diagonal):.4f}")
print(f"Users with positive similarity: {np.sum(off_diagonal > 0)} out of {len(off_diagonal)}")

"""**Recommendation Function**"""

def recommend_books(user_id, k=10, top_n=10):
    """
    Recommend books for a user using collaborative filtering with normalized ratings

    Parameters:
    -----------
    user_id : int
        The User-ID to get recommendations for
    k : int
        Number of similar users to consider (default: 10)
    top_n : int
        Number of top books to recommend (default: 10)

    Returns:
    --------
    pd.DataFrame
        DataFrame with recommended Book-Title, Book-Author, and ISBN
    """

    # Get user index from user_id
    try:
        user_index = user_book_matrix.index.get_loc(user_id)
    except KeyError:
        return f"User ID {user_id} not found in the dataset"

    # Adjust k if it's larger than available similar users
    k = min(k, len(user_book_matrix) - 1)

    # Get similarity scores for the user
    similarity_scores = user_similarity[user_index].copy()

    # Only consider users with positive similarity
    similarity_scores[similarity_scores <= 0] = 0

    # Find k most similar users (excluding the user themselves)
    similar_users_indices = np.argsort(similarity_scores)[::-1][1:k+1]

    # Remove users with zero similarity
    similar_users_indices = similar_users_indices[similarity_scores[similar_users_indices] > 0]

    if len(similar_users_indices) == 0:
        return "No similar users found for recommendations"


    # Get weights based on similarity
    weights = similarity_scores[similar_users_indices]
    weights = weights / np.sum(weights)  # Normalize weights

    # Calculate weighted average ratings from similar users
    avg_book_ratings = np.zeros(ratings_matrix.shape[1])
    for idx, user_idx in enumerate(similar_users_indices):
        # Use original ratings (not normalized)
        user_ratings = ratings_matrix[user_idx]
        avg_book_ratings += user_ratings * weights[idx]

    # Remove books already rated by the user (set to -1 to exclude)
    user_rated_mask = ratings_matrix[user_index] > 0
    avg_book_ratings[user_rated_mask] = -1

    # Get top_n books with highest weighted average ratings
    top_book_indices = np.argsort(avg_book_ratings)[::-1]
    top_book_indices = top_book_indices[avg_book_ratings[top_book_indices] >= 0][:top_n]

    if len(top_book_indices) == 0:
        return "No new books to recommend"

    recommended_isbns = user_book_matrix.columns[top_book_indices]

    # Get book details from original books_data
    recommended_books = books_data[books_data["ISBN"].isin(recommended_isbns)][
        ["ISBN", "Book-Title", "Book-Author", "Year-Of-Publication", "Publisher"]
    ]

    # Add predicted ratings
    recommended_books = recommended_books.copy()
    predicted_ratings = []
    for isbn in recommended_books["ISBN"]:
        col_idx = user_book_matrix.columns.get_loc(isbn)
        predicted_ratings.append(avg_book_ratings[col_idx])

    recommended_books["Predicted-Rating"] = predicted_ratings
    recommended_books = recommended_books.sort_values("Predicted-Rating", ascending=False)

    return recommended_books

"""**Test the Recommendation System**"""

# Get a sample user ID
sample_user_id = user_book_matrix.index[2]
print(f"Getting recommendations for User ID: {sample_user_id}\n")

# Get recommendations
recommendations = recommend_books(user_id=sample_user_id, k=10, top_n=10)
print("Recommended Books:")
print(recommendations)

"""**Wrapper Function with User Name/ID**"""

def book_recommender(user_id, k=10, top_n=10):
    """
    Wrapper function for book recommendations

    Parameters:
    -----------
    user_id : int
        The User-ID to get recommendations for
    k : int
        Number of similar users to consider (default: 10)
    top_n : int
        Number of top books to recommend (default: 10)

    Returns:
    --------
    pd.DataFrame
        DataFrame with ISBN, Book-Title, Book-Author, Year, Publisher, and Predicted-Rating
    """

    recommendations = recommend_books(user_id=user_id, k=k, top_n=top_n)

    if isinstance(recommendations, str):
        return recommendations

    return recommendations.reset_index(drop=True)

